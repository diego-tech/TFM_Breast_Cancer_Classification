{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea5fdff6",
   "metadata": {
    "id": "ea5fdff6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement Torch==1.8.1 (from versions: 2.0.0, 2.0.1)\n",
      "ERROR: No matching distribution found for Torch==1.8.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: TorchVision in c:\\users\\diego\\anaconda3\\envs\\uem_env\\lib\\site-packages (0.15.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\diego\\anaconda3\\envs\\uem_env\\lib\\site-packages (from TorchVision) (1.23.5)\n",
      "Requirement already satisfied: requests in c:\\users\\diego\\anaconda3\\envs\\uem_env\\lib\\site-packages (from TorchVision) (2.28.1)\n",
      "Requirement already satisfied: torch==2.0.1 in c:\\users\\diego\\anaconda3\\envs\\uem_env\\lib\\site-packages (from TorchVision) (2.0.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\diego\\anaconda3\\envs\\uem_env\\lib\\site-packages (from TorchVision) (9.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\diego\\anaconda3\\envs\\uem_env\\lib\\site-packages (from torch==2.0.1->TorchVision) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\diego\\anaconda3\\envs\\uem_env\\lib\\site-packages (from torch==2.0.1->TorchVision) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\diego\\anaconda3\\envs\\uem_env\\lib\\site-packages (from torch==2.0.1->TorchVision) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\diego\\anaconda3\\envs\\uem_env\\lib\\site-packages (from torch==2.0.1->TorchVision) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\diego\\anaconda3\\envs\\uem_env\\lib\\site-packages (from torch==2.0.1->TorchVision) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\diego\\anaconda3\\envs\\uem_env\\lib\\site-packages (from requests->TorchVision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\diego\\anaconda3\\envs\\uem_env\\lib\\site-packages (from requests->TorchVision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\diego\\anaconda3\\envs\\uem_env\\lib\\site-packages (from requests->TorchVision) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\diego\\anaconda3\\envs\\uem_env\\lib\\site-packages (from requests->TorchVision) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\diego\\anaconda3\\envs\\uem_env\\lib\\site-packages (from jinja2->torch==2.0.1->TorchVision) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\diego\\anaconda3\\envs\\uem_env\\lib\\site-packages (from sympy->torch==2.0.1->TorchVision) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "#INSTALACIÃ“N DE LIBRERIAS\n",
    "!pip install Torch==1.8.1\n",
    "!pip install TorchVision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0612e71",
   "metadata": {
    "id": "a0612e71"
   },
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import os\n",
    "import shutil\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ca3ad46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if pickle is correct\n",
    "# Train data\n",
    "with open('../IDC_train.dat', 'rb') as f:\n",
    "    (X_train, y_train) = pickle.load(f)\n",
    "\n",
    "# Test data\n",
    "with open('../IDC_test.dat', 'rb') as f:\n",
    "    (X_test, y_test) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6bffa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir datos de entrenamiento a tensores\n",
    "X_train = torch.tensor(X_train)\n",
    "y_train = torch.tensor(y_train)\n",
    "\n",
    "# Convertir datos de prueba a tensores\n",
    "X_test = torch.tensor(X_test)\n",
    "y_test = torch.tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7db53521",
   "metadata": {
    "id": "7db53521",
    "outputId": "884113e4-3e82-48f6-c28e-c63c1f3edebe"
   },
   "outputs": [],
   "source": [
    "# Define custom dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "test_dataset = CustomDataset(X_test, y_test)\n",
    "\n",
    "# Define the model architecture\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_neurons):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, num_neurons, 3)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.fc = nn.Linear(num_neurons*50*50*3, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "            \n",
    "        x = self.fc(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Define the function to create the model\n",
    "# Define the function to create the model\n",
    "def crear_modelo(num_neurons):\n",
    "    model = Model(num_neurons)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    return model, criterion, optimizer\n",
    "\n",
    "# Define the grid of parameters\n",
    "param_grid = {\n",
    "    'num_neurons': [10, 20, 30, 40, 50],\n",
    "}\n",
    "# Perform grid search\n",
    "best_accuracy = 0.0\n",
    "best_params = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0325c09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([222019, 50, 50, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b673d26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x123210 and 75000x1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)\n\u001b[0;32m      6\u001b[0m inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(batch_size, \u001b[38;5;241m*\u001b[39minput_shape)\n\u001b[1;32m----> 8\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\UEM_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[23], line 32\u001b[0m, in \u001b[0;36mModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     29\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(x)\n\u001b[0;32m     30\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten(x)\n\u001b[1;32m---> 32\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(x)\n\u001b[0;32m     33\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid(x)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\UEM_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\UEM_env\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x123210 and 75000x1)"
     ]
    }
   ],
   "source": [
    "# Forward Pass para probar si la red funciona\n",
    "model = Model(10)\n",
    "\n",
    "batch_size = 1\n",
    "input_shape = (3, 224, 224)\n",
    "inputs = torch.randn(batch_size, *input_shape)\n",
    "\n",
    "outputs = model(inputs)\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3fd4c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.7173, -0.7130, -0.4417,  ...,  2.0409,  1.9807,  0.6817],\n",
       "          [ 1.8647,  0.2237, -0.3349,  ..., -1.1041, -1.9769, -0.8542],\n",
       "          [ 0.8280, -0.8898,  0.1478,  ..., -1.0272,  0.1604, -0.4046],\n",
       "          ...,\n",
       "          [-1.9202, -0.2081,  1.1455,  ..., -1.1719, -0.4182, -2.4341],\n",
       "          [ 0.6424,  0.8525, -0.4016,  ..., -0.2898, -0.3073,  0.3027],\n",
       "          [ 0.1467,  0.6620,  0.6757,  ...,  0.8763, -0.0287, -0.7981]],\n",
       "\n",
       "         [[ 0.5437,  0.7964, -0.7785,  ..., -1.0187, -1.0723,  0.9971],\n",
       "          [-0.6546,  0.3824, -0.1794,  ..., -0.9837,  0.0746, -0.0525],\n",
       "          [-1.0634, -0.6565,  0.2763,  ..., -1.5390,  0.3812, -0.5767],\n",
       "          ...,\n",
       "          [-0.7119, -0.3076,  0.3942,  ...,  0.4839, -0.6875, -0.1747],\n",
       "          [ 1.2536, -1.2595,  1.2237,  ...,  0.7604, -0.5051,  0.9017],\n",
       "          [ 0.1850, -0.4167,  0.7353,  ...,  2.1681,  0.7902, -0.4878]],\n",
       "\n",
       "         [[-0.6784, -1.6887,  0.0856,  ..., -0.4539,  0.3251,  1.1501],\n",
       "          [ 1.4816,  0.0906, -0.8970,  ..., -0.1167, -0.6746,  0.3686],\n",
       "          [ 1.7797, -1.9040, -0.5845,  ..., -0.6227,  2.4139,  0.8927],\n",
       "          ...,\n",
       "          [-1.6416,  2.0094, -0.3228,  ..., -0.4123, -0.0970, -0.7166],\n",
       "          [-0.5436,  2.5091, -0.2264,  ...,  0.6173,  1.1144, -0.3510],\n",
       "          [ 0.9866, -2.1430,  0.9089,  ...,  0.0375,  2.1260, -0.3605]]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4cf86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in ParameterGrid(param_grid):\n",
    "    model, criterion, optimizer = crear_modelo(params['num_neurons'], params['hidden_size'], params['num_layers'])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)\n",
    "\n",
    "    for epoch in range(10):\n",
    "        model.train()\n",
    "        image_counter = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            image_counter += inputs.size(0)\n",
    "            print(f\"Epoch: {epoch+1}, Processed images: {image_counter}\")\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.float().unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                outputs = model(inputs)\n",
    "                predicted = (outputs >= 0.5).squeeze().long()\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = correct / total\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_params = params\n",
    "\n",
    "print(\"Best Accuracy:\", best_accuracy)\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
